# KyroDB Configuration Example (YAML)
#
# Copy this file to config.yaml and customize for your deployment.
# All settings are optional - defaults are production-ready.
#
# Environment variables override config file values:
#   KYRODB__SERVER__PORT=50051 ./kyrodb_server
#   KYRODB__CACHE__CAPACITY=50000 ./kyrodb_server --config config.yaml

# Server Configuration
server:
  # gRPC server host (IPv4 or IPv6)
  host: "127.0.0.1"
  
  # gRPC server port
  port: 50051
  
  # HTTP observability port (auto-calculated as gRPC port + 1000 if omitted)
  # http_port: 51051

  # HTTP observability host (defaults to server.host if omitted)
  # Use this to bind observability endpoints to a restricted interface.
  # http_host: "127.0.0.1"

  # Authentication policy for HTTP observability endpoints:
  # - disabled: no auth on /metrics,/health,/ready,/slo
  # - metrics_and_slo: require auth for /metrics and /slo
  # - all: require auth for all observability endpoints
  # Note: any non-disabled value requires auth.enabled=true.
  # observability_auth: metrics_and_slo
  
  # Maximum concurrent connections
  max_connections: 10000
  
  # Connection idle timeout (seconds)
  connection_timeout_secs: 300
  
  # Graceful shutdown timeout (seconds)
  shutdown_timeout_secs: 30

# Authentication (API keys for gRPC and optionally observability)
auth:
  # Enable API key auth
  # NOTE: Keeping this false is only valid for loopback/local deployments.
  # Production with non-loopback gRPC bind requires auth.enabled=true.
  enabled: false

  # Path to API keys file (YAML)
  # api_keys_file: "data/api_keys.yaml"

# Cache Configuration (Hybrid Semantic Cache)
cache:
  # Maximum number of vectors to cache
  # Customer A might use 1000, Customer B might use 100,000
  capacity: 10000
  
  # Cache eviction strategy: lru, learned, or abtest
  # - lru: Simple LRU eviction (baseline)
  # - learned: Hybrid Semantic Cache with a learned hotness predictor
  # - abtest: A/B test between LRU and Learned
  strategy: learned
  
  # Training interval for Hybrid Semantic Cache (seconds)
  training_interval_secs: 600  # 10 minutes

  # Training window (how far back to consider accesses, in seconds)
  training_window_secs: 3600

  # Recency decay half-life (seconds)
  recency_halflife_secs: 1800

  # Enable the background retraining task in the server.
  # If disabled, the learned predictor will remain in bootstrap mode.
  enable_training_task: true

  # Access logger window size (number of recent access events retained for training).
  # Larger values can improve training stability at the cost of memory.
  logger_window_size: 1000000

  # Predictor capacity multiplier relative to cache capacity.
  # The predictor stores hotness metadata; keeping this larger than cache capacity
  # reduces churn for workloads with a large working set.
  predictor_capacity_multiplier: 4

  # Query search cache (L1b) settings
  query_cache_capacity: 100
  # Cosine similarity threshold for semantic query matches (topâ€‘k reuse).
  # Tune per embedding model and workload.
  query_cache_similarity_threshold: 0.52

  # Optional override for hot-tier max age (seconds).
  # If omitted, the server uses training_interval_secs.
  # hot_tier_max_age_secs: 600
  
  # Minimum access count before training the predictor
  min_training_samples: 100

  # Admission threshold (0.0-1.0) for the learned strategy.
  admission_threshold: 0.15

  # Auto-tune admission threshold based on cache utilization.
  auto_tune_threshold: true

  # Target cache utilization (0.0-1.0) used by auto-tuning.
  target_utilization: 0.85

# HNSW Configuration (Vector Search Backend)
hnsw:
  # Maximum number of vectors in index
  max_elements: 100000
  
  # Number of bidirectional links per node (M parameter)
  # Higher M = better recall, more memory
  m: 16
  
  # Size of dynamic candidate list during construction
  # Higher ef_construction = better index quality, slower build
  ef_construction: 200
  
  # Size of dynamic candidate list during search
  # Higher ef_search = better recall, slower queries
  ef_search: 50
  
  # Vector dimension (must match your embeddings)
  # Common values: 768 (sentence transformers), 1536 (OpenAI), 384 (MiniLM)
  dimension: 768
  
  # Distance metric: cosine, euclidean, or innerproduct
  distance: cosine

  # Disable L2-normalization checks for inner-product vectors (performance opt-out)
  disable_normalization_check: false

# Persistence Configuration (WAL + Snapshots)
persistence:
  # Data directory for WAL and snapshots
  data_dir: "./data"
  
  # WAL fsync interval (milliseconds, 0 = sync on every write when fsync_policy=data_only)
  # Lower = more durable, slower writes
  wal_flush_interval_ms: 100
  
  # fsync policy: none, data_only, or full
  # - none: No fsync (fastest, data loss on crash)
  # - data_only: fsync data only (good balance)
  # - full: fsync data + metadata (safest, slowest)
  fsync_policy: data_only
  
  # Snapshot interval (number of WAL mutations including inserts and deletes, 0 = disabled)
  # Legacy key "snapshot_interval_inserts" is still accepted as an alias.
  snapshot_interval_mutations: 10000
  
  # Maximum WAL size before rotation (bytes)
  max_wal_size_bytes: 104857600  # 100 MB
  
  # Enable automatic crash recovery on startup
  enable_recovery: true

  # If true, allows starting with a fresh empty DB when recovery fails.
  # WARNING: This can discard access to existing data if the on-disk state is corrupted.
  allow_fresh_start_on_recovery_failure: false

# SLO Configuration (Service Level Objectives)
slo:
  # P99 latency threshold (milliseconds)
  # Breach alert if P99 > this value
  p99_latency_ms: 10.0
  
  # Cache hit rate threshold (0.0-1.0)
  # Breach alert if hit rate < this value
  cache_hit_rate: 0.70
  
  # Error rate threshold (0.0-1.0)
  # Breach alert if error rate > this value
  error_rate: 0.001
  
  # Availability threshold (0.0-1.0)
  # Breach alert if availability < this value
  availability: 0.999
  
  # Minimum sample size before alerting (prevent false positives during startup)
  min_samples: 100

# Rate Limiting Configuration
rate_limit:
  # Enable rate limiting (disable for trusted internal networks)
  enabled: false
  
  # Maximum queries per second per connection
  max_qps_per_connection: 1000
  
  # Maximum queries per second globally
  max_qps_global: 100000
  
  # Burst capacity (token bucket size)
  burst_capacity: 10000

# Logging Configuration
logging:
  # Log level: trace, debug, info, warn, error
  level: info
  
  # Log format: text (human-readable) or json (for aggregation)
  format: text
  
  # Log file path (omit for stdout only)
  # file: "./logs/kyrodb.log"
  
  # Enable log rotation
  rotation: true
  
  # Maximum log file size before rotation (bytes)
  max_file_size_bytes: 104857600  # 100 MB
  
  # Maximum number of rotated log files to keep
  max_files: 10
